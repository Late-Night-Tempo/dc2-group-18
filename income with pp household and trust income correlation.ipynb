{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_pay(year):\n",
    "    \"\"\"\n",
    "    Year goes from 2010 to 2022 (incl)\n",
    "    \n",
    "    a) First, it estimates the houshold income per borough using average household size,\n",
    "       employement rate and median weekly work-based earning pp.\n",
    "       \n",
    "    b) Then, it plots a map per borough with a color gradient showing houshold income \n",
    "       per borough for @year.\n",
    "    \"\"\"\n",
    "    # Validate the input year\n",
    "    if year < 2010 or year > 2022:\n",
    "        raise ValueError(\"Year must be between 2010 and 2022\")\n",
    "\n",
    "    # Load the shapefile\n",
    "    shapefile_path = \"London-wards-2018/London-wards-2018_ESRI/London_Ward.shp\"\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "    # Dissolve the geometries by the borough column to aggregate wards into boroughs\n",
    "    boroughs = gdf.dissolve(by='DISTRICT').reset_index()\n",
    "\n",
    "    # Load the pay CSV data\n",
    "    pay_csv_path = \"pay.csv\"\n",
    "    pay_data = pd.read_csv(pay_csv_path)\n",
    "    \n",
    "    # Extract relevant columns for the specified year\n",
    "    year_str = str(year)\n",
    "    pay_data = pay_data[['Area', year_str]]\n",
    "\n",
    "    # Replace non-numeric values ('#', '!') with NaN and convert to float\n",
    "    pay_data[year_str] = pd.to_numeric(pay_data[year_str].replace(['#', '!'], np.nan), errors='coerce')\n",
    "\n",
    "    # Set the 'Area' column as the index\n",
    "    pay_data = pay_data.set_index('Area')\n",
    "\n",
    "    # Rename the column for consistency\n",
    "    pay_data.columns = ['Pay']\n",
    "\n",
    "    # Adjust the name in the CSV data to match 'City of Westminster'\n",
    "    pay_data = pay_data.rename(index={'Westminster': 'City of Westminster'})\n",
    "\n",
    "    # Load the unemployment data\n",
    "    unemployment_csv_path = \"unemployement_edit.csv\"\n",
    "    unemployment_data = pd.read_csv(unemployment_csv_path)\n",
    "\n",
    "    # Extract unemployment rate for the specified year\n",
    "    unemployment_data['Year'] = pd.to_datetime(unemployment_data['Date']).dt.year\n",
    "    unemployment_rate = unemployment_data[unemployment_data['Year'] == year]['Unemployment rate: London'].values[0]\n",
    "\n",
    "    # Compute the employment rate\n",
    "    employment_rate = 1 - unemployment_rate\n",
    "\n",
    "    # Calculate the estimated household income\n",
    "    pay_data['Estimated_Household_Income'] = pay_data['Pay'] * employment_rate * 2.6 * 52\n",
    "\n",
    "    # Merge the pay data with the borough geometries using 'DISTRICT' and 'Area'\n",
    "    boroughs = boroughs.merge(pay_data, left_on='DISTRICT', right_index=True, how='left')\n",
    "\n",
    "    # Check for any boroughs with missing data\n",
    "    missing_data_boroughs = boroughs[boroughs['Estimated_Household_Income'].isnull()]\n",
    "    print(\"Boroughs with missing data:\\n\", missing_data_boroughs['DISTRICT'].tolist())\n",
    "\n",
    "    # Plot the borders of the boroughs and fill with estimated household income data for the specified year\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    boroughs.boundary.plot(ax=ax, color='black')\n",
    "    boroughs.plot(column='Estimated_Household_Income', cmap='Blues_r', legend=True, ax=ax, missing_kwds={\"color\": \"red\", \"label\": \"Missing data\"})\n",
    "\n",
    "    # Remove axes and extra edges\n",
    "    ax.set_axis_off()\n",
    "    ax.margins(0)\n",
    "\n",
    "    # Add legend for missing data\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handles.append(plt.Line2D([0], [0], marker='o', color='w', label='Missing data', markerfacecolor='red', markersize=10))\n",
    "    ax.legend(handles=handles, loc='upper right')\n",
    "\n",
    "    plt.title(f'Estimated Household Income per borough in {year} (in £)')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "plot_pay(2022)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493302b",
   "metadata": {},
   "source": [
    "the pattern is the same as in the previous plot (that showcased work-based income pp) \n",
    "\n",
    "im multiplying the previously plotted variable by constant terms and plotting it again, of course the visualization wouldnt change ..\n",
    "\n",
    "I realize what i did was pointless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee09a84",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de05ab9a",
   "metadata": {},
   "source": [
    "Plot correlation\n",
    "- maybe that would help to closely observe the relaltionship between trust and work-based income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc30ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "\n",
    "def load_pay_data(year):\n",
    "    # Load the CSV data\n",
    "    csv_path = \"pay.csv\"\n",
    "    csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract relevant columns for the specified year\n",
    "    year_str = str(year)\n",
    "    pay_data = csv_data[['Area', year_str]]\n",
    "\n",
    "    # Replace non-numeric values ('#') with NaN and convert to float\n",
    "    pay_data[year_str] = pd.to_numeric(pay_data[year_str].replace('#', np.nan), errors='coerce')\n",
    "\n",
    "    # Remove duplicates\n",
    "    pay_data = pay_data.drop_duplicates(subset=['Area'])\n",
    "\n",
    "    # Set the 'Area' column as the index\n",
    "    pay_data = pay_data.set_index('Area')\n",
    "\n",
    "    # Rename the column for consistency\n",
    "    pay_data.columns = ['Pay']\n",
    "\n",
    "    # Adjust the name in the CSV data to match 'City of Westminster'\n",
    "    pay_data = pay_data.rename(index={'Westminster': 'City of Westminster'})\n",
    "\n",
    "    return pay_data\n",
    "\n",
    "def load_trust_data(year):\n",
    "    # Load the CSV data for trust in MPS\n",
    "    csv_path = \"pas_data_borough (1).csv\"\n",
    "    csv_data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Filter the data for 'Trust MPS' measure and the specified year\n",
    "    trust_mps_data = csv_data[(csv_data['Measure'] == 'Trust MPS') & (csv_data['Date'].str.contains(str(year)))]\n",
    "\n",
    "    # Extract relevant columns\n",
    "    trust_data = trust_mps_data[['Borough', 'Proportion']].copy()\n",
    "\n",
    "    # Replace non-numeric values ('#') with NaN and convert to float\n",
    "    trust_data.loc[:, 'Proportion'] = pd.to_numeric(trust_data['Proportion'].replace('#', np.nan), errors='coerce')\n",
    "\n",
    "    # Remove duplicates\n",
    "    trust_data = trust_data.drop_duplicates(subset=['Borough'])\n",
    "\n",
    "    # Set the 'Borough' column as the index\n",
    "    trust_data = trust_data.set_index('Borough')\n",
    "\n",
    "    # Rename the column for consistency\n",
    "    trust_data.columns = ['Trust']\n",
    "\n",
    "    # Adjust the name in the CSV data to match 'City of Westminster'\n",
    "    trust_data = trust_data.rename(index={'Westminster': 'City of Westminster'})\n",
    "\n",
    "    return trust_data\n",
    "\n",
    "def plot_correlation(pay_year, trust_year):\n",
    "    # Load the pay data\n",
    "    pay_data = load_pay_data(pay_year)\n",
    "\n",
    "    # Load the trust data\n",
    "    trust_data = load_trust_data(trust_year)\n",
    "\n",
    "    # Merge the datasets\n",
    "    merged_data = pay_data.merge(trust_data, left_index=True, right_index=True)\n",
    "\n",
    "    # Calculate the correlation coefficient\n",
    "    correlation = merged_data.corr().iloc[0, 1]\n",
    "    print(f\"Correlation coefficient between income and trust: {correlation:.2f}\")\n",
    "\n",
    "    # Apply LOWESS smoothing\n",
    "    lowess_smoothed = lowess(merged_data['Trust'], merged_data['Pay'], frac=0.3)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig = px.scatter(merged_data, x='Pay', y='Trust',\n",
    "                     labels={'Pay': 'Median Weekly Work-Based Earnings (£)', 'Trust': 'Trust in MPS Proportion'},\n",
    "                     title=f'Correlation between Income and Trust in MPS in {pay_year}',\n",
    "                     hover_name=merged_data.index)\n",
    "\n",
    "    # Add the LOWESS trend line\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=lowess_smoothed[:, 0],\n",
    "            y=lowess_smoothed[:, 1],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=2),\n",
    "            name='LOWESS trend',\n",
    "            opacity=0.5\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update layout for better appearance\n",
    "    fig.update_layout(\n",
    "        title=f'Correlation between Income and Trust in MPS in {pay_year}',\n",
    "        xaxis_title='Median Weekly Work-Based Earnings (£)',\n",
    "        yaxis_title='Trust in MPS Proportion',\n",
    "        template='plotly_white'\n",
    "    )\n",
    "#     fig.write_image(f'Income_and_Trust_{pay_year}.png')\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "# Example usage\n",
    "plot_correlation(2019, 2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a3489",
   "metadata": {},
   "source": [
    "The above scatter plot that shows the correlation between the 2 variables (trust and work based earnings) and shows a non-linear regression line that shows the ‘trend’\n",
    "\n",
    "- perfect correlation (when the variables are the same) is a diagonal line (e.g. f(x) = x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c0a91",
   "metadata": {},
   "source": [
    "The weakcorrelation between these 2 variables suggests that the income of people in London is not something linked to police trust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa846f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f6d14b1",
   "metadata": {},
   "source": [
    "It seems that income isn't related with trust in a meaningful way; \n",
    "\n",
    "That probably means we cant come up with recommendations to give to MPS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2516dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
